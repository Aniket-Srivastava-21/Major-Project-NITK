# -*- coding: utf-8 -*-
"""2D_Image_Segmentation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10jL25tawewv3m2yp2tOyuvmWukl3poAU

## Download Datasets
"""

TRAIN_PATH = '/tmp/train_dataset.tif'

"""### Open Image Stack"""

import numpy as np

from skimage import io

from keras.models import Model
from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda

from matplotlib import pyplot as plt

from sklearn.model_selection import train_test_split

image_stack = io.imread(TRAIN_PATH)
image_stack.shape

"""### Split Large Images into small 256x256 Patches"""

def patchify_image(img_stack, patch_size):
    patches = []

    for i in range(img_stack.shape[0]):
        for row in range(img_stack.shape[1] // patch_size):
            for col in range(img_stack.shape[2] // patch_size):
                patch = img_stack[i, patch_size * row : patch_size * (row + 1), patch_size * col : patch_size * (col + 1)]
                patches.append(patch)

    return patches

IMG_SIZE = 256

patches = patchify_image(image_stack, IMG_SIZE)

train_array = np.array(patches)
train_array.shape

io.imshow(train_array[0])

io.imshow(image_stack[0])

"""### Repeat the same for Masks"""

LABEL_PATH = '/tmp/train_dataset_labels.tif'

label_stack = io.imread(LABEL_PATH)

label_patches = patchify_image(label_stack, IMG_SIZE)

train_labels = np.array(label_patches)
print(train_labels.shape)

io.imshow(train_array[5])

io.imshow(train_labels[5])

"""### Expand Dimensions and scaling b/w 0 and 1"""

image_dataset = np.expand_dims(train_array, axis = 3) / 255.0
mask_dataset = np.expand_dims(train_labels, axis = 3) / 255.0

print(image_dataset.shape, mask_dataset.shape)

"""### Train test split 90 : 10"""

X_train, X_test, y_train, y_test = train_test_split(image_dataset, mask_dataset, test_size = 0.1, random_state = 10)
print(f"X_train Shape: {X_train.shape}, X_test Shape: {X_test.shape}")

"""## Sanity check
### Very Important in Image Segmentation to check whether the labels corresponds to the its image
"""

image_number = np.random.randint(0, X_train.shape[0])
print(f"Image number: {image_number}")
plt.figure(figsize = (16, 10))
plt.subplot(121)
plt.title("Input Image")
plt.imshow(np.reshape(X_train[image_number], (IMG_SIZE, IMG_SIZE)), cmap = 'gray')
plt.subplot(122)
plt.title("Input Label")
plt.imshow(np.reshape(y_train[image_number], (IMG_SIZE, IMG_SIZE)), cmap = 'gray')
plt.show()

"""## Designing The Model"""
"""### U-Net model Architecture"""

def simple_unet_model(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS):
#Build the model
    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))
    #s = Lambda(lambda x: x / 255)(inputs)   #No need for this if we normalize our inputs beforehand
    s = inputs

    #Contraction path
    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)
    c1 = Dropout(0.1)(c1)
    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)
    p1 = MaxPooling2D((2, 2))(c1)
    
    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)
    c2 = Dropout(0.1)(c2)
    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)
    p2 = MaxPooling2D((2, 2))(c2)
     
    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)
    c3 = Dropout(0.2)(c3)
    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)
    p3 = MaxPooling2D((2, 2))(c3)
     
    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)
    c4 = Dropout(0.2)(c4)
    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)
    p4 = MaxPooling2D(pool_size=(2, 2))(c4)
     
    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)
    c5 = Dropout(0.3)(c5)
    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)
    
    #Expansive path 
    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)
    u6 = concatenate([u6, c4])
    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)
    c6 = Dropout(0.2)(c6)
    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)
     
    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)
    u7 = concatenate([u7, c3])
    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)
    c7 = Dropout(0.2)(c7)
    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)
     
    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)
    u8 = concatenate([u8, c2])
    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)
    c8 = Dropout(0.1)(c8)
    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)
     
    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)
    u9 = concatenate([u9, c1], axis=3)
    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)
    c9 = Dropout(0.1)(c9)
    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)
     
    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)
     
    model = Model(inputs=[inputs], outputs=[outputs])
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    model.summary()
    
    return model

model = simple_unet_model(IMG_SIZE, IMG_SIZE, 1)

history = model.fit(
                    X_train, 
                    y_train, 
                    batch_size=16,
                    epochs = 20,
                    validation_data = (X_test, y_test),
                    shuffle = False
                    )

model.save('mitochondria-image-seg.hdf5')

print(model.evaluate(X_test, y_test))

y_preds = model.predict(X_test)
y_pred_thresholded = y_preds > 0.5

intersection = np.logical_and(y_pred_thresholded, y_test)
union = np.logical_or(y_pred_thresholded, y_test)

IoU = np.sum(intersection) / np.sum(union)

print(f"IoU Score: {IoU}")

X_test.shape, np.expand_dims(X_test[0][:,:,0], axis = 0).shape

number = np.random.randint(0, X_test.shape[0])

print(number)

plt.figure(figsize = (16, 6))

plt.subplot(131)
plt.title("Testing Image")
plt.imshow(np.reshape(X_test[number][:,:,0], (IMG_SIZE, IMG_SIZE)), cmap = 'gray')

plt.subplot(132)

pred = model.predict(np.expand_dims(X_test[number], axis = 0))
pred_thresholded = pred > 0.5

plt.title("Testing Prediction")
plt.imshow(pred_thresholded[0,:,:,0], cmap = 'gray')

plt.subplot(133)
plt.title("Testing Label")
plt.imshow(np.reshape(y_test[number], (IMG_SIZE, IMG_SIZE)), cmap = 'gray')

